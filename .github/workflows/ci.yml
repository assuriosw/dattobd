---
name: ci
on:
  - push

env:
  AWS_ACCESS_KEY_ID:     ${{ secrets.AWS_ACCESS_KEY_ID }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  AWS_DEFAULT_REGION:    ${{ secrets.AWS_REGION }}

jobs:
  build-packages:
    name: Build Packages
    runs-on:
      - metal
      - ${{ matrix.arch }}

    strategy:
      matrix:
        distro: [
          amazon2,
          centos7, centos8,
          debian8, debian9, debian10, debian11,
          fedora31, fedora32, fedora34, fedora35, fedora36,
          ubuntu2004, ubuntu2204
        ]
        arch: [ amd64 ]
        include:
          - distro: amazon2
            arch: arm64
          # FIXME: CentOS 8 on ARM64 is not yet supported.
          # See https://github.com/elastio/elastio-snap/issues/125 for more details.
          #- distro: centos8
          #  arch: arm64
          - distro: debian10
            arch: arm64
          # FIXME: Debian 11 on ARM64 is not yet supported.
          # See https://github.com/elastio/elastio-snap/issues/124 for more details.
          #- distro: debian11
          #  arch: arm64
          - distro: fedora35
            arch: arm64
          - distro: fedora36
            arch: arm64
          - distro: ubuntu2204
            arch: arm64

    steps:
      - name: Checkout sources
        uses: actions/checkout@v2

      - name: Set ENV
        if: always()
        env:
          DISTRO: ${{ matrix.distro }}
          ARCH:   ${{ matrix.arch }}
        run: .github/scripts/set_env.sh

      - name: Check ENV
        run: .github/scripts/check_env.sh

      - name: Start a box
        if: always()
        env:
          AWS_ACCESS_KEY_ID:  ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_DEFAULT_REGION: ${{ secrets.AWS_REGION }}
        run: .github/scripts/start_box.sh

      - name: Boot Fedora 32 into kernel 5.9
        if: "${{ matrix.distro == 'fedora32' && matrix.arch == 'amd64' }}"
        run: |
          vagrant ssh ${{env.INSTANCE_NAME}} -c '
            sudo yum localinstall -y https://kojipkgs.fedoraproject.org//packages/kernel/5.9.16/100.fc32/x86_64/kernel-core-5.9.16-100.fc32.x86_64.rpm
            sudo yum localinstall -y https://kojipkgs.fedoraproject.org//packages/kernel/5.9.16/100.fc32/x86_64/kernel-modules-5.9.16-100.fc32.x86_64.rpm
            sudo yum localinstall -y https://kojipkgs.fedoraproject.org//packages/kernel/5.9.16/100.fc32/x86_64/kernel-5.9.16-100.fc32.x86_64.rpm
            sudo yum localinstall -y https://kojipkgs.fedoraproject.org//packages/kernel/5.9.16/100.fc32/x86_64/kernel-devel-5.9.16-100.fc32.x86_64.rpm
            sudo reboot now' || true
          sleep 5
        working-directory: ${{env.BOX_DIR}}

      # Amazon 2 has installed devtoolset-8 which upgrades GCC from 7.3.1 to 8.3.1.
      # The new gcc doesn't compile rpm packages properly, because of the /usr/lib/rpm/redhat/macros provided
      # by the package system-rpm-config-9.1.0-76.amzn2.0.13.noarch. And this macros has compilation flags applicable
      # for GCC 7 and already removed from GCC 8. The workaround is to disable devtoolset-8 on the next build step.
      - name: Remove devtoolset
        if: "${{ matrix.distro == 'amazon2' && matrix.arch == 'arm64' }}"
        run: vagrant ssh ${{env.INSTANCE_NAME}} -c 'sudo rm /etc/profile.d/enable-llvm-toolset.sh'
        working-directory: ${{env.BOX_DIR}}

      - name: Build packages
        run: vagrant ssh ${{env.INSTANCE_NAME}} -c 'make ${PKG_TYPE}'
        working-directory: ${{env.BOX_DIR}}

      - name: Collect artifacts
        run: vagrant ssh ${{env.INSTANCE_NAME}} -c 'repobuild/collect_artifacts.sh'
        working-directory: ${{env.BOX_DIR}}

      - name: Build kernel module
        run: vagrant ssh ${{env.INSTANCE_NAME}} -c 'sudo make'
        working-directory: ${{env.BOX_DIR}}

      - name: Install kernel module
        run: |
          vagrant ssh ${{env.INSTANCE_NAME}} -c 'sudo make install'
          vagrant ssh ${{env.INSTANCE_NAME}} -c 'sudo make uninstall'
        working-directory: ${{env.BOX_DIR}}

      - name: Run tests (loop device)
        run: vagrant ssh ${{env.INSTANCE_NAME}} -c "cd tests && sudo ./elio-test.sh"
        working-directory: ${{env.BOX_DIR}}
        # For now tests are taking 10-20 seconds. But they can hang.
        # 5 minutes seems to be reasonable timeout.
        timeout-minutes: 5

      - name: Show dmesg
        if: always()
        run: vagrant ssh ${{env.INSTANCE_NAME}} -c "sudo dmesg -c"
        working-directory: ${{env.BOX_DIR}}
        timeout-minutes: 1

      - name: Attach qcow2 disk
        run: |
          ARCH=$(uname -m)
          qemu-img create -f qcow2 ${TEST_IMAGE} 1G
          [ ${ARCH} != "x86_64" ] && VIRSH_FLAGS="--config" || true
          virsh attach-disk --domain ${BOX_DIR##*/}_${INSTANCE_NAME} --source ${TEST_IMAGE} --target vdb --driver qemu --subdriver qcow2 --targetbus virtio ${VIRSH_FLAGS-}
          # ARM64 boxes don't support "hot plug" w/o reboot
          if [ ${ARCH} != "x86_64" ]; then
            virsh destroy --domain ${BOX_DIR##*/}_${INSTANCE_NAME}
            virsh start --domain ${BOX_DIR##*/}_${INSTANCE_NAME}
            while ! vagrant ssh ${INSTANCE_NAME} -c 'uptime'; do
              echo "Waiting..."
              sleep 1
            done
          fi
          vagrant ssh ${{env.INSTANCE_NAME}} -c 'echo -e "n\np\n\n\n\nw" | sudo fdisk /dev/vdb'
        working-directory: ${{env.BOX_DIR}}

      - name: Run tests (qcow2 disk)
        run: vagrant ssh ${{env.INSTANCE_NAME}} -c "cd tests && sudo ./elio-test.sh /dev/vdb1"
        working-directory: ${{env.BOX_DIR}}
        timeout-minutes: 5

      - name: Show dmesg
        if: always()
        run: vagrant ssh ${{env.INSTANCE_NAME}} -c "sudo dmesg -c"
        working-directory: ${{env.BOX_DIR}}
        timeout-minutes: 1

      - name: Detach external drive
        if: always()
        run: |
          if virsh domblklist ${BOX_DIR##*/}_${INSTANCE_NAME} --details | grep "file" | awk '{ print $NF }' | grep ${TEST_IMAGE} ; then
              virsh detach-disk --domain ${BOX_DIR##*/}_${INSTANCE_NAME} ${TEST_IMAGE}
          fi
          rm -f ${TEST_IMAGE}

      - name: Upload artifacts
        run: |
          excl_ptrn="*GPG-KEY"
          # We have to avoid a race condition when package like elastio-snap-dkms_X.XX.XX-1debian11_all.deb is uploaded from
          # 2 Debian 11 VMs amd64 and arm64 at the same time to the same location.
          [ $(uname -m) != "x86_64" ] && [ -f /etc/debian_version ] && excl_ptrn=$excl_ptrn",*_all.deb" || true
          vagrant ssh ${{env.INSTANCE_NAME}} -c 'AWS_SECRET_ACCESS_KEY='"'$AWS_SECRET_ACCESS_KEY'"' repobuild/upload.sh \
            --source repobuild/artifacts/ \
            --bucket artifacts.assur.io \
            --target /linux/elastio-snap/${SOURCE_BRANCH}/${GITHUB_RUN_NUMBER}/${PKG_TYPE} \
            --exclude '"'$excl_ptrn'"''
        working-directory: ${{env.BOX_DIR}}

      - name: Destroy a box
        if: always()
        run: .github/scripts/destroy_box.sh

  manifest:
    name: Artifacts manifest
    needs: build-packages
    runs-on:
      - baremetal

    steps:
      - name: Checkout sources
        uses: actions/checkout@v2

      - name: Make manifest
        run: echo $GITHUB_RUN_NUMBER > latest && cat latest | grep -E '^[0-9]+$'

      - name: Upload manifest
        run: repobuild/upload.sh
          --source latest
          --bucket artifacts.assur.io
          --target /linux/elastio-snap/$(.github/scripts/detect_branch.sh)

  dispatch-packaging-repo:
    name: Trigger repo upload
    needs: manifest
    runs-on:
      - baremetal

    steps:
      - name: Checkout sources
        uses: actions/checkout@v2

      - name: Dispatch packaging repo
        env:
          REPO_HOOK_TOKEN: ${{ secrets.REPO_HOOK_TOKEN }}
        run: .github/scripts/dispatch_packaging.sh
